{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aomJUY_gvXed",
   "metadata": {
    "id": "aomJUY_gvXed"
   },
   "source": [
    "Initialise code for google colab\n",
    "\n",
    "Mount google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GAjcLhjCgpxv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4450,
     "status": "ok",
     "timestamp": 1671446275823,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "GAjcLhjCgpxv",
    "outputId": "e34c2966-478f-439f-c4bb-ea2036820438"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_addons as tfa\n",
    "print(tfa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.11\n",
    "!pip install tensorflow-addons==0.19"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "J3iW3Uff2Jyh",
   "metadata": {
    "id": "J3iW3Uff2Jyh"
   },
   "source": [
    "Create data base files under google colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D1ubGnuD2CXZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88494,
     "status": "ok",
     "timestamp": 1671446369482,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "D1ubGnuD2CXZ",
    "outputId": "79fec16a-f91c-413d-f571-dd30d3435e5f"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/MyDrive/data_equalize.zip' -d '/content/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sMjhaRhC-HQM",
   "metadata": {
    "id": "sMjhaRhC-HQM"
   },
   "source": [
    "For Luc because my archive made on mac create a __MACOSX folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iAyxXHqB935f",
   "metadata": {
    "executionInfo": {
     "elapsed": 2940,
     "status": "ok",
     "timestamp": 1671446392319,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "iAyxXHqB935f"
   },
   "outputs": [],
   "source": [
    "%rm -rf /content/__MACOSX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "nnQuhv17x7hK",
   "metadata": {
    "id": "nnQuhv17x7hK"
   },
   "source": [
    "Define working directory to our jupyter repertory:\n",
    "* because path to the different repertories (./data, ./output...) are define relatevly to jupyter one\n",
    "* let import _mypath which add ./lib to python path in order to import our own define libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9WqQG1rjjHGq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1671446474973,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "9WqQG1rjjHGq",
    "outputId": "89a23162-4e46-4cd1-f96d-5c67bb7996aa"
   },
   "outputs": [],
   "source": [
    "# for google colab use\n",
    "%cd /content/gdrive/MyDrive/covid-19-xRay/jupyter\n",
    "db_work_dir = '/content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local use\n",
    "db_work_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c135d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import _mypath\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "import joblib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport database.data_path\n",
    "%aimport database.dataset\n",
    "\n",
    "from database.data_path import build_data_paths\n",
    "from database.dataset import build_dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "image_height = 256\n",
    "image_width = 256\n",
    "image_size = [image_height, image_width]\n",
    "input_shape = (image_height, image_width, 3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "label_smoothing = 0.1\n",
    "patience = 5\n",
    "min_delta = 0.005\n",
    "\n",
    "# data augmentation\n",
    "scale = 1. / 255.\n",
    "flip = \"horizontal_and_vertical\"\n",
    "rotation_factor = 10. / 360.\n",
    "zoom_height_factor = 0.2\n",
    "zoom_width_factor = 0.2\n",
    "\n",
    "mlp_head_units = [512, 256]  # Size of the dense layers of the final classifier\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76855cab",
   "metadata": {
    "id": "76855cab"
   },
   "source": [
    "Build paths and variables for reading data base hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "db_name = 'data'\n",
    "db_path = os.path.join(db_work_dir, db_name)\n",
    "\n",
    "# output\n",
    "output_path = os.path.join('..', 'output', 'transfer_learning')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "log_path = os.path.join(output_path, 'log')\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "ckpt_path = os.path.join(output_path, 'ckpt')\n",
    "if not os.path.exists(ckpt_path):\n",
    "    os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "metric_path = os.path.join(output_path, 'metric')\n",
    "if not os.path.exists(metric_path):\n",
    "    os.makedirs(metric_path, exist_ok=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fec096c7",
   "metadata": {
    "id": "fec096c7"
   },
   "source": [
    "Structure to manage paths in data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1271f47",
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1671446527378,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "a1271f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['../data/hard_wheat_device1', '../data/soft_wheat_device1', '../data/barley_device1', '../data/corn_device1']\n",
      "['../data/soft_wheat_device2', '../data/barley_device2']\n"
     ]
    }
   ],
   "source": [
    "grain_types = [\"hard_wheat\", \"soft_wheat\", \"barley\", \"corn\"]\n",
    "n_labels = len(grain_types)\n",
    "print(n_labels)\n",
    "\n",
    "data_paths_device1, labels_device1 = build_data_paths(db_path, grain_types, [\"device1\"])\n",
    "print(data_paths_device1)\n",
    "data_paths_device2, labels_device2 = build_data_paths(db_path, grain_types, [\"device2\"])\n",
    "print(data_paths_device2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 files belonging to 1 classes.\n",
      "Found 51 files belonging to 1 classes.\n",
      "Found 51 files belonging to 1 classes.\n",
      "<_ConcatenateDataset element_spec=(TensorSpec(shape=(256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.int32, name=None))>\n",
      "[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n",
      "Found 11 files belonging to 1 classes.\n",
      "Found 11 files belonging to 1 classes.\n",
      "<_ConcatenateDataset element_spec=(TensorSpec(shape=(256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.int32, name=None))>\n",
      "[[0, 1, 0, 0], [0, 0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "ds_device1 = build_dataset(data_paths_device1, labels_device1, image_size=image_size, shuffle=False)\n",
    "print(ds_device1)\n",
    "print(labels_device1)\n",
    "\n",
    "ds_device2 = build_dataset(data_paths_device2, labels_device2, image_size=image_size, shuffle=False)\n",
    "print(ds_device2)\n",
    "print(labels_device2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:14:20.507926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [26]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-20 14:14:20.508499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [26]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([1 0 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([1 0 0 0], shape=(4,), dtype=int32)\n",
      "-----------\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([1 0 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([1 0 0 0], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(ds_device1)\n",
    "print(dataset_size)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "valid_size = int(0.10 * dataset_size)\n",
    "\n",
    "ds = ds_device1.shuffle(dataset_size, seed=123, reshuffle_each_iteration=False)\n",
    "# ds = ds_device1\n",
    "ds_train = ds.take(train_size)\n",
    "ds_test = ds.skip(train_size)\n",
    "ds_valid = ds_test.take(valid_size)\n",
    "ds_test = ds_test.skip(valid_size)\n",
    "\n",
    "# for elem in ds_test:\n",
    "#     print(elem[1])\n",
    "# print(\"-----------\")\n",
    "# for elem in ds_test:\n",
    "#     print(elem[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "      layers.Rescaling(scale=scale),\n",
    "      layers.RandomFlip(flip),\n",
    "      layers.RandomRotation(rotation_factor),\n",
    "      layers.RandomZoom(height_factor=zoom_height_factor, width_factor=zoom_width_factor),\n",
    "    ],\n",
    "    name='data_augmentation'\n",
    ")\n",
    "norm_layer = layers.Normalization()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproc = tf.keras.applications.vgg16.preprocess_input(augmented)\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "# preproc = tf.keras.applications.vgg19.preprocess_input(input)\n",
    "# baseModel = VGG19(weights=\"imagenet\", include_top=False,input_tensor=layers.Input(shape=(image_size, image_size, 3)))\n",
    "# preproc = tf.keras.applications.DenseNet201.preprocess_input(input)\n",
    "# baseModel = DenseNet201(weights=\"imagenet\", include_top=False,input_tensor=layers.Input(shape=(image_size, image_size, 3)))\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "augmented = data_augmentation(inputs)\n",
    "base = baseModel(augmented)\n",
    "# construct the head of the model that will be placed on top of the\n",
    "head = layers.AveragePooling2D(pool_size=(8, 8))(base)\n",
    "head = layers.Flatten(name=\"flatten\")(head)\n",
    "features = mlp(head, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "\n",
    "# Classify outputs.\n",
    "softmax = layers.Dense(n_labels, activation='softmax', kernel_initializer='random_normal')(features)\n",
    "\n",
    "# Create the Keras model.\n",
    "model = keras.Model(inputs=inputs, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_8 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " data_augmentation (Sequenti  (None, 256, 256, 3)      0         \n",
      " al)                                                             \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 1, 1, 512)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,109,700\n",
      "Trainable params: 395,012\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:15:02.436797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_23' with dtype string and shape [51]\n",
      "\t [[{{node Placeholder/_23}}]]\n",
      "2023-06-20 14:15:02.437328: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [26]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.8049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:15:50.484746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype string and shape [51]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-06-20 14:15:50.485518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype string and shape [51]\n",
      "\t [[{{node Placeholder/_15}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80000, saving model to ../output/transfer_learning/ckpt/transfer_leraning_VGG16_weights.hdf5\n",
      "31/31 [==============================] - 62s 2s/step - loss: 0.7142 - accuracy: 0.8049 - val_loss: 0.7284 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.8699\n",
      "Epoch 2: val_accuracy improved from 0.80000 to 1.00000, saving model to ../output/transfer_learning/ckpt/transfer_leraning_VGG16_weights.hdf5\n",
      "31/31 [==============================] - 63s 2s/step - loss: 0.6215 - accuracy: 0.8699 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.9187\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "31/31 [==============================] - 73s 2s/step - loss: 0.5656 - accuracy: 0.9187 - val_loss: 0.5210 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.9024\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "31/31 [==============================] - 66s 2s/step - loss: 0.5614 - accuracy: 0.9024 - val_loss: 0.5862 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.9675\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "31/31 [==============================] - 69s 2s/step - loss: 0.4950 - accuracy: 0.9675 - val_loss: 0.4571 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.9756\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "31/31 [==============================] - 76s 2s/step - loss: 0.4695 - accuracy: 0.9756 - val_loss: 0.4385 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.9919\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "31/31 [==============================] - 71s 2s/step - loss: 0.4529 - accuracy: 0.9919 - val_loss: 0.4120 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137efc400>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from run_exp.standard import run_experiment\n",
    "\n",
    "model_name = 'transfer_leraning_VGG16'\n",
    "run_experiment(\n",
    "  model,\n",
    "  ds_train, ds_valid, ds_test,\n",
    "  batch_size=batch_size, num_epochs=num_epochs,\n",
    "  learning_rate=learning_rate, weight_decay=weight_decay,\n",
    "  from_logits=False, label_smoothing=label_smoothing,\n",
    "  patience=patience, min_delta=min_delta,\n",
    "  log_path=log_path, ckpt_path=ckpt_path,\n",
    "  prefix=model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'transfer_leraning_VGG16'\n",
    "checkpoint_filename = os.path.join(ckpt_path, model_name + '_weights.hdf5')\n",
    "model.load_weights(checkpoint_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:28:23.861316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype string and shape [51]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-06-20 14:28:23.862457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_23' with dtype string and shape [51]\n",
      "\t [[{{node Placeholder/_23}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:28:38.906318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [26]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-20 14:28:38.906881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_23' with dtype string and shape [51]\n",
      "\t [[{{node Placeholder/_23}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../output/transfer_learning/metric/transfer_leraning_VGG16_conf_mat.joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%aimport run_exp.test\n",
    "from run_exp.test import compile_test_model\n",
    "\n",
    "y_test_pd, y_pred_pd, accuracy, conf_mat, report = compile_test_model(\n",
    "    model,\n",
    "    ds_test,\n",
    "    batch_size,\n",
    "    from_logits=False,\n",
    "    label_smoothing=label_smoothing\n",
    ")\n",
    "\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "print(report)\n",
    "f_name = os.path.join(metric_path, model_name + '_report.txt')\n",
    "with open(f_name, \"w\") as text_file:\n",
    "  text_file.write(report)\n",
    "\n",
    "conf_mat\n",
    "f_name = os.path.join(metric_path, model_name + '_conf_mat.joblib')\n",
    "joblib.dump(conf_mat, f_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:28:57.053607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype string and shape [11]\n",
      "\t [[{{node Placeholder/_7}}]]\n",
      "2023-06-20 14:28:57.053909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [11]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 7s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:29:04.522972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [11]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-20 14:29:04.523322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [11]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 50.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.50      1.00      0.67        11\n",
      "\n",
      "    accuracy                           0.50        22\n",
      "   macro avg       0.25      0.50      0.33        22\n",
      "weighted avg       0.25      0.50      0.33        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luc/.local/share/virtualenvs/inarix-PNHHY2Cu/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/luc/.local/share/virtualenvs/inarix-PNHHY2Cu/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/luc/.local/share/virtualenvs/inarix-PNHHY2Cu/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../output/transfer_learning/metric/transfer_leraning_VGG16_device2_conf_mat.joblib']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%aimport run_exp.test\n",
    "from run_exp.test import compile_test_model\n",
    "\n",
    "y_test_pd, y_pred_pd, accuracy, conf_mat, report = compile_test_model(\n",
    "    model,\n",
    "    ds_device2, batch_size,\n",
    "    from_logits=False,\n",
    "    label_smoothing=label_smoothing\n",
    ")\n",
    "\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "print(report)\n",
    "f_name = os.path.join(metric_path, model_name + '_device2_report.txt')\n",
    "with open(f_name, \"w\") as text_file:\n",
    "  text_file.write(report)\n",
    "\n",
    "conf_mat\n",
    "f_name = os.path.join(metric_path, model_name + '_device2_conf_mat.joblib')\n",
    "joblib.dump(conf_mat, f_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid-19-xRay-gI8RPtYc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec449b28ee1275c8ed3472cdab9bc054b62d41bc2731e9c066fdcbfc125fb022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
